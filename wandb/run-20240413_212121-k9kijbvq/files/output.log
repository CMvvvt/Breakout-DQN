/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: [33mWARN: The environment Breakout-v0 is out of date. You should consider upgrading to version `v4`.
  logger.deprecation(
1000
2000
3000
4000
5000
6000
7000
8000
9000
10000
0it [00:00, ?it/s]Traceback (most recent call last):
  File "/Users/ming/Courses/5180/project/dqn-breakout/main.py", line 140, in <module>
    main()
  File "/Users/ming/Courses/5180/project/dqn-breakout/main.py", line 98, in main
    loss = agent.learn()
  File "/Users/ming/Courses/5180/project/dqn-breakout/agent.py", line 125, in learn
    target_values = rewards + self.gamma * next_q_values * (1 - dones)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/_tensor.py", line 40, in wrapped
    return f(*args, **kwargs)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/_tensor.py", line 941, in __rsub__
    return _C._VariableFunctions.rsub(self, other)
RuntimeError: Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.
Traceback (most recent call last):
  File "/Users/ming/Courses/5180/project/dqn-breakout/main.py", line 140, in <module>
    main()
  File "/Users/ming/Courses/5180/project/dqn-breakout/main.py", line 98, in main
    loss = agent.learn()
  File "/Users/ming/Courses/5180/project/dqn-breakout/agent.py", line 125, in learn
    target_values = rewards + self.gamma * next_q_values * (1 - dones)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/_tensor.py", line 40, in wrapped
    return f(*args, **kwargs)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/_tensor.py", line 941, in __rsub__
    return _C._VariableFunctions.rsub(self, other)
RuntimeError: Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.
Saving training model...
actions's shape should be [32]: torch.Size([32])
rewards's shape should be [32]: torch.Size([32])
dones's shape should be [32]: torch.Size([32])
Qvalues shape should be [32, 4] torch.Size([32, 4])
Values shape should be [32, 1] torch.Size([32, 1])