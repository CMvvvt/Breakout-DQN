









293it [00:19, 12.34it/s]
reward of episode 0: 2.0















621it [00:50, 10.73it/s]
reward of episode 1: 3.0



707it [00:57, 13.09it/s]/Users/ming/Courses/5180/project/dqn-breakout/agent.py:60: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:248.)
  state = torch.tensor([observation], dtype=torch.float32).permute(0, 2, 3, 1)





837it [01:08, 12.59it/s]
reward of episode 2: 1.0










1069it [01:28, 12.83it/s]
reward of episode 3: 1.0







1223it [01:42, 10.67it/s]
reward of episode 4: 0.0







1386it [01:55, 10.93it/s]
reward of episode 5: 0.0












1681it [02:20, 12.91it/s]
reward of episode 6: 2.0









1878it [02:38, 11.17it/s]
reward of episode 7: 1.0








2051it [02:53, 12.76it/s]
reward of episode 8: 0.0









2275it [03:12, 13.61it/s]
reward of episode 9: 1.0








2479it [03:28, 12.89it/s]
reward of episode 10: 0.0









2701it [03:46, 13.36it/s]
reward of episode 11: 1.0










2953it [04:06, 11.09it/s]
reward of episode 12: 1.0











3158it [04:30, 12.82it/s]
reward of episode 13: 1.0












3438it [04:54, 10.70it/s]
reward of episode 14: 2.0











3661it [05:15, 12.15it/s]
reward of episode 15: 1.0












3918it [05:40, 12.90it/s]
reward of episode 16: 1.0











4188it [06:02, 13.37it/s]
reward of episode 17: 2.0










4436it [06:22, 11.18it/s]
reward of episode 18: 1.0









4658it [06:40, 12.78it/s]
reward of episode 19: 1.0






4814it [06:52, 12.87it/s]
reward of episode 20: 0.0







4996it [07:06, 13.23it/s]
reward of episode 21: 0.0









5218it [07:24, 13.35it/s]
reward of episode 22: 1.0







5396it [07:38, 13.30it/s]
reward of episode 23: 0.0











5676it [08:00, 13.29it/s]
reward of episode 24: 2.0









5910it [08:18, 11.29it/s]
reward of episode 25: 1.0







6094it [08:32, 13.10it/s]
reward of episode 26: 0.0







6260it [08:46,  7.58it/s]
reward of episode 27: 0.0













6586it [09:12, 13.16it/s]
reward of episode 28: 2.0













6920it [09:38, 13.01it/s]
reward of episode 29: 3.0











7208it [10:00, 13.14it/s]
reward of episode 30: 2.0









7431it [10:18,  6.46it/s]
reward of episode 31: 1.0














7769it [10:46, 12.48it/s]
reward of episode 32: 3.0










8015it [11:06, 11.81it/s]
reward of episode 33: 1.0










8265it [11:27, 12.83it/s]
reward of episode 34: 1.0









8485it [11:45, 12.94it/s]
reward of episode 35: 1.0
















8857it [12:16, 12.42it/s]
reward of episode 36: 3.0















9190it [12:46,  8.42it/s]
reward of episode 37: 3.0







9357it [13:01, 12.52it/s]
reward of episode 38: 0.0










9570it [13:21,  9.92it/s]
reward of episode 39: 0.0














9908it [13:48, 10.68it/s]
reward of episode 40: 3.0






10056it [14:01, 12.26it/s]
reward of episode 41: 0.0










10272it [14:21, 12.60it/s]
reward of episode 42: 1.0







10448it [14:35, 12.78it/s]
reward of episode 43: 0.0






10610it [14:48, 11.35it/s]Traceback (most recent call last):
  File "/Users/ming/Courses/5180/project/dqn-breakout/main.py", line 100, in <module>
    main()
  File "/Users/ming/Courses/5180/project/dqn-breakout/main.py", line 66, in main
    next_obeservation, reward, done, info = env.step(action)
  File "/Users/ming/Courses/5180/project/dqn-breakout/utils.py", line 76, in step
    im, reward, done, info, _ = self.env.step(action)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py", line 56, in step
    return self.env.step(action)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py", line 51, in step
    return self.env.step(action)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/shimmy/atari_env.py", line 294, in step
    reward += self.ale.act(action)
KeyboardInterrupt
Traceback (most recent call last):
  File "/Users/ming/Courses/5180/project/dqn-breakout/main.py", line 100, in <module>
    main()
  File "/Users/ming/Courses/5180/project/dqn-breakout/main.py", line 66, in main
    next_obeservation, reward, done, info = env.step(action)
  File "/Users/ming/Courses/5180/project/dqn-breakout/utils.py", line 76, in step
    im, reward, done, info, _ = self.env.step(action)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py", line 56, in step
    return self.env.step(action)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py", line 51, in step
    return self.env.step(action)
  File "/Users/ming/.pyenv/versions/3.10.13/lib/python3.10/site-packages/shimmy/atari_env.py", line 294, in step
    reward += self.ale.act(action)
KeyboardInterrupt